{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementação do paper **Adversarial Discriminative Domain Adaptation**\n",
    "\n",
    "Esse paper propoe um framework de treinamento adversario, em que a rede de extração de features tenta confundir o discriminador, o qual tenta prever se determinado batch de imagens pertence ao source ou ao target do dominio. Os resultados mostraram a eficiencia em aplicar treinamento adversario em adaptação de dominio.\n",
    "\n",
    "*Paper disponivel em: https://arxiv.org/abs/1702.05464"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "q2S7dOX_P3X8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.datasets import SVHN, MNIST\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OAUVoXT4Q5-Z"
   },
   "source": [
    "## 1. Download do Dataset\n",
    "\n",
    "Para essa implementação, utilizaremos o dataset MNIST e o SVHN. Além disso aplicaremos uma transformação simples, normalizando-o com 0.5 na media e variancia e redimensionando a imagem para o tamanho 28x28 com 3 canais.\n",
    "\n",
    "A depender de seu hardware, será necessario diminuir o batch_size para poupar recursos no treinamento em GPU/CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "6VoUXrnbQ7-U"
   },
   "outputs": [],
   "source": [
    "transform_ = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Resize((28, 28)),\n",
    "        transforms.Lambda(lambda x: x.repeat(3, 1, 1))\n",
    "    ]\n",
    ")\n",
    "\n",
    "mnist_dataset = datasets.MNIST(\n",
    "    root=\"./data/\",\n",
    "    train=True,\n",
    "    transform=transform_,\n",
    "    download=True\n",
    ")\n",
    "\n",
    "mnist_data_loader = torch.utils.data.DataLoader(\n",
    "    dataset=mnist_dataset,\n",
    "    batch_size=128,\n",
    "    shuffle=True,drop_last = True,\n",
    "    pin_memory=True, num_workers=7\n",
    ")\n",
    "\n",
    "mnist_dataset = datasets.MNIST(\n",
    "    root=\"./data/\",\n",
    "    train=False,\n",
    "    transform=transform_,\n",
    "    download=True\n",
    ")\n",
    "\n",
    "mnist_data_loader_test = torch.utils.data.DataLoader(\n",
    "    dataset=mnist_dataset,\n",
    "    batch_size=128,\n",
    "    shuffle=False,drop_last = True,\n",
    "    pin_memory=True, num_workers=7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "I8eM0vsHSPXm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: ./data/train_32x32.mat\n"
     ]
    }
   ],
   "source": [
    "usps_dataset = datasets.SVHN(\n",
    "    root=\"./data/\",\n",
    "    transform=transforms.Compose([transforms.ToTensor(),transforms.Resize((28, 28))]),\n",
    "    download=True\n",
    ")\n",
    "\n",
    "usps_data_loader_train = torch.utils.data.DataLoader(\n",
    "    dataset=usps_dataset,\n",
    "    batch_size=128,\n",
    "    shuffle=True,drop_last = True,\n",
    "    pin_memory=True, num_workers=7\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z007A-X2RpLg"
   },
   "source": [
    "## 2. Criação dos Modelos\n",
    "\n",
    "Conforme descrito no paper de Eric Tzeng,, devemos criar tres modelos: discriminador, classificador e extrator de features.\n",
    "\n",
    "* Extrator de Features: Essa rede é uma sequencia de convoluções que tem como output uma vetor de features de tamanho 100.\n",
    "\n",
    "* Classificador: A rede de classificação tem como input um vetor de features de tamanho 100 e retorna a probabilidade entre as 10 classes do MNIST (0, 1, 2, ..., 9).\n",
    "\n",
    "* Discriminador: Para o discriminador, a rede terá como input o vetor de features de tamanho 100 e retornará uma classificação entre duas classes (0 e 1 ou \"Source\" e \"Target\").\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "gp1cyDVTRuwV"
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.fully_conec = nn.Linear(100, 10)\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 10, kernel_size=3),\n",
    "            nn.BatchNorm2d(10),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(10, 25, kernel_size=3),\n",
    "            nn.BatchNorm2d(25),\n",
    "            nn.MaxPool2d(kernel_size=4),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "    \n",
    "    def forward(self, input):\n",
    "        output = self.encoder(input).view(-1, 100)\n",
    "        return self.fully_conec(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "7BlByY-cVSZN"
   },
   "outputs": [],
   "source": [
    "class Classificador(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Classificador, self).__init__()\n",
    "        self.fully_connected = nn.Sequential(\n",
    "            nn.Linear(50, 10)\n",
    "        )\n",
    "    \n",
    "    def forward(self, input):\n",
    "        out = self.fully_connected(input)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, target=False):\n",
    "        super(CNN, self).__init__()\n",
    "        self.encoder = Encoder()\n",
    "        self.classificador = Classificador()\n",
    "        \n",
    "        if target:\n",
    "            for param in self.classificador.parameters():\n",
    "                param.requires_grad = False\n",
    "    \n",
    "    def forward(self, input):\n",
    "        return self.classificador(self.encoder(input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = nn.Sequential(\n",
    "    nn.Linear(50, 500),\n",
    "    nn.LeakyReLU(0.2),\n",
    "    nn.Linear(500, 500),\n",
    "    nn.LeakyReLU(0.2),\n",
    "    nn.Linear(500, 2),\n",
    ").cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ue3T9rKRXo2t"
   },
   "source": [
    "## 3. Treinando o Classificador\n",
    "\n",
    "Primeiramente, vamos treinar a rede de extração de features e o classificador, utilizando o dataset do SVHN para que posteriormente seja possivel adaptar o dominio para o dataset MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LlASAngSXmtA",
    "outputId": "1ef39e11-0b4f-40e2-c160-059eca441ec5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██████████████████▏                                                         | 12/50 [01:10<03:41,  5.84s/it]Exception in thread Thread-224:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/andre/anaconda3/lib/python3.9/threading.py\", line 973, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/andre/anaconda3/lib/python3.9/threading.py\", line 910, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/andre/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/pin_memory.py\", line 49, in _pin_memory_loop\n",
      "    do_one_step()\n",
      "  File \"/home/andre/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/pin_memory.py\", line 26, in do_one_step\n",
      "    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/andre/anaconda3/lib/python3.9/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/home/andre/anaconda3/lib/python3.9/site-packages/torch/multiprocessing/reductions.py\", line 305, in rebuild_storage_fd\n",
      "    fd = df.detach()\n",
      "  File \"/home/andre/anaconda3/lib/python3.9/multiprocessing/resource_sharer.py\", line 57, in detach\n",
      "    with _resource_sharer.get_connection(self._id) as conn:\n",
      "  File \"/home/andre/anaconda3/lib/python3.9/multiprocessing/resource_sharer.py\", line 86, in get_connection\n",
      "    c = Client(address, authkey=process.current_process().authkey)\n",
      "  File \"/home/andre/anaconda3/lib/python3.9/multiprocessing/connection.py\", line 513, in Client\n",
      "    answer_challenge(c, authkey)\n",
      "  File \"/home/andre/anaconda3/lib/python3.9/multiprocessing/connection.py\", line 762, in answer_challenge\n",
      "    response = connection.recv_bytes(256)        # reject large message\n",
      "  File \"/home/andre/anaconda3/lib/python3.9/multiprocessing/connection.py\", line 221, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/andre/anaconda3/lib/python3.9/multiprocessing/connection.py\", line 419, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/andre/anaconda3/lib/python3.9/multiprocessing/connection.py\", line 388, in _recv\n",
      "    raise EOFError\n",
      "EOFError\n",
      " 24%|██████████████████▏                                                         | 12/50 [01:13<03:51,  6.09s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [46]\u001b[0m, in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m         loss \u001b[38;5;241m=\u001b[39m criterion(prediction, ground_truth)\n\u001b[1;32m     22\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 23\u001b[0m         \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Loss = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/autograd/__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    194\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "CNN_source = CNN().cuda()\n",
    "\n",
    "CNN_source.train()\n",
    "\n",
    "optimizer = optim.Adam(CNN_source.parameters())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    for step, (images, ground_truth) in enumerate(usps_data_loader_train):\n",
    "        images = images.cuda()\n",
    "        ground_truth = ground_truth.cuda()\n",
    "\n",
    "        prediction =CNN_source(images)\n",
    "        \n",
    "        loss = criterion(prediction, ground_truth)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "print(f\" Loss = {loss}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por fim, podemos salvar o modelo treinado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "def save(log_dir, state_dict, is_best):\n",
    "    checkpoint_path = os.path.join(log_dir, 'checkpoint.pt')\n",
    "    torch.save(state_dict, checkpoint_path)\n",
    "    if is_best:\n",
    "        best_model_path = os.path.join(log_dir, 'best_model.pt')\n",
    "        shutil.copyfile(checkpoint_path, best_model_path)\n",
    "\n",
    "state_dict = {\n",
    "    'model': CNN_source.state_dict(),\n",
    "    'optimizer': optimizer.state_dict(),\n",
    "    'epoch': 10,\n",
    "    'val/acc': loss,\n",
    "}\n",
    "save(\"./\", state_dict, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Calculando Acuracia para SVHN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NnEMgvZKnmP9",
    "outputId": "7bf7278b-f2d7-4786-d345-71d1925c87d2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8438592657342657"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "CNN_source.eval()\n",
    "\n",
    "accuracy = 0\n",
    "n = 0\n",
    "for (images, ground_truth) in usps_data_loader_train:\n",
    "    n+=1\n",
    "    images = images.cuda()\n",
    "    ground_truth = ground_truth.cuda()\n",
    "    prediction = CNN_source(images)\n",
    "    pred_max = prediction.data.max(1)[1]\n",
    "    accuracy += accuracy_score(ground_truth.data.cpu(), pred_max.cpu())\n",
    "\n",
    "\n",
    "accuracy/n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Calculando Acuracia para MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W14udfSVnL3E",
    "outputId": "0d0aab38-7889-4c57-b347-924f7573ec0c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4619"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CNN_source.eval()\n",
    "\n",
    "accuracy = 0\n",
    "\n",
    "for (images, ground_truth) in mnist_data_loader_test:\n",
    "    images = images.cuda()\n",
    "    ground_truth = ground_truth.cuda()\n",
    "\n",
    "    prediction = CNN_source(images)\n",
    "    pred_max = prediction.data.max(1)[1]\n",
    "    accuracy += pred_max.eq(ground_truth.data).cpu().sum()\n",
    "\n",
    "accuracy = accuracy.item()/len(mnist_data_loader_test.dataset)\n",
    "\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como pudemos ver, para o dataset SVHN, tivemos uma acuracia de ~84%, porem, uma acuracia de 46% para o dataset MNIST.\n",
    "\n",
    "Por serem datasets com o mesmo dominio, podemos aplicar as tecnicas descritas no paper para melhorar o resultado do MNIST."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qRaeHhAusWs2"
   },
   "source": [
    "## 6. Treinamento com Descriminador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "lvczaLYLsacB",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 0; Discriminator Loss= 0.381192684173584; Target Encoder Loss = 1.6581473350524902; Target ACC=0.3797242254273504\n",
      "Epoch = 1; Discriminator Loss= 0.4029332101345062; Target Encoder Loss = 2.7219181060791016; Target ACC=0.4188034188034188\n",
      "Epoch = 2; Discriminator Loss= 0.43447619676589966; Target Encoder Loss = 2.0638458728790283; Target ACC=0.3385750534188034\n",
      "Epoch = 3; Discriminator Loss= 0.4020487666130066; Target Encoder Loss = 2.1944973468780518; Target ACC=0.3480902777777778\n",
      "Epoch = 4; Discriminator Loss= 0.4178672134876251; Target Encoder Loss = 2.327063798904419; Target ACC=0.37837206196581197\n",
      "Epoch = 5; Discriminator Loss= 0.3326684236526489; Target Encoder Loss = 1.8382474184036255; Target ACC=0.34132946047008544\n",
      "Epoch = 6; Discriminator Loss= 0.3535568416118622; Target Encoder Loss = 1.7790955305099487; Target ACC=0.3447516025641026\n",
      "Epoch = 7; Discriminator Loss= 0.3385522961616516; Target Encoder Loss = 2.18906307220459; Target ACC=0.3482238247863248\n",
      "Epoch = 8; Discriminator Loss= 0.39075201749801636; Target Encoder Loss = 1.8213307857513428; Target ACC=0.3608940972222222\n",
      "Epoch = 9; Discriminator Loss= 0.29537418484687805; Target Encoder Loss = 2.587427854537964; Target ACC=0.39044137286324787\n",
      "Epoch = 10; Discriminator Loss= 0.5105113387107849; Target Encoder Loss = 1.7388873100280762; Target ACC=0.37580128205128205\n",
      "Epoch = 11; Discriminator Loss= 0.3290158212184906; Target Encoder Loss = 2.2132742404937744; Target ACC=0.3931290064102564\n",
      "Epoch = 12; Discriminator Loss= 0.32950472831726074; Target Encoder Loss = 1.9595690965652466; Target ACC=0.3878872863247863\n",
      "Epoch = 13; Discriminator Loss= 0.4438488781452179; Target Encoder Loss = 1.9072659015655518; Target ACC=0.3866686698717949\n",
      "Epoch = 14; Discriminator Loss= 0.34269848465919495; Target Encoder Loss = 1.7688394784927368; Target ACC=0.419788327991453\n",
      "Epoch = 15; Discriminator Loss= 0.39815422892570496; Target Encoder Loss = 1.577905535697937; Target ACC=0.3978031517094017\n",
      "Epoch = 16; Discriminator Loss= 0.4038155674934387; Target Encoder Loss = 1.7197932004928589; Target ACC=0.39917200854700857\n",
      "Epoch = 17; Discriminator Loss= 0.4090675115585327; Target Encoder Loss = 1.6843810081481934; Target ACC=0.413795405982906\n",
      "Epoch = 18; Discriminator Loss= 0.38993269205093384; Target Encoder Loss = 1.8018330335617065; Target ACC=0.41177550747863245\n",
      "Epoch = 19; Discriminator Loss= 0.42748746275901794; Target Encoder Loss = 1.643547773361206; Target ACC=0.38673544337606836\n",
      "Epoch = 20; Discriminator Loss= 0.40726253390312195; Target Encoder Loss = 1.4951512813568115; Target ACC=0.41988848824786323\n",
      "Epoch = 21; Discriminator Loss= 0.4919372498989105; Target Encoder Loss = 1.6286404132843018; Target ACC=0.3671875\n",
      "Epoch = 22; Discriminator Loss= 0.45382019877433777; Target Encoder Loss = 1.7110602855682373; Target ACC=0.39646768162393164\n",
      "Epoch = 23; Discriminator Loss= 0.4086691737174988; Target Encoder Loss = 1.6642487049102783; Target ACC=0.4459969284188034\n",
      "Epoch = 24; Discriminator Loss= 0.4053118824958801; Target Encoder Loss = 1.7243317365646362; Target ACC=0.4093215811965812\n",
      "Epoch = 25; Discriminator Loss= 0.444486141204834; Target Encoder Loss = 1.736616611480713; Target ACC=0.4008079594017094\n",
      "Epoch = 26; Discriminator Loss= 0.3516175448894501; Target Encoder Loss = 1.7411651611328125; Target ACC=0.4165665064102564\n",
      "Epoch = 27; Discriminator Loss= 0.4603399336338043; Target Encoder Loss = 1.688172459602356; Target ACC=0.41442975427350426\n",
      "Epoch = 28; Discriminator Loss= 0.431875079870224; Target Encoder Loss = 1.6755794286727905; Target ACC=0.4129440438034188\n",
      "Epoch = 29; Discriminator Loss= 0.5394186973571777; Target Encoder Loss = 1.543485403060913; Target ACC=0.3937800480769231\n",
      "Epoch = 30; Discriminator Loss= 0.4202980697154999; Target Encoder Loss = 1.4706918001174927; Target ACC=0.3986545138888889\n",
      "Epoch = 31; Discriminator Loss= 0.4593369960784912; Target Encoder Loss = 1.6881053447723389; Target ACC=0.4184528579059829\n",
      "Epoch = 32; Discriminator Loss= 0.42145687341690063; Target Encoder Loss = 1.4314242601394653; Target ACC=0.4266493055555556\n",
      "Epoch = 33; Discriminator Loss= 0.5224050283432007; Target Encoder Loss = 1.4293358325958252; Target ACC=0.42416199252136755\n",
      "Epoch = 34; Discriminator Loss= 0.4279462695121765; Target Encoder Loss = 1.719943881034851; Target ACC=0.43977029914529914\n",
      "Epoch = 35; Discriminator Loss= 0.49885106086730957; Target Encoder Loss = 1.295571208000183; Target ACC=0.4027610844017094\n",
      "Epoch = 36; Discriminator Loss= 0.47336530685424805; Target Encoder Loss = 1.5762701034545898; Target ACC=0.4174512553418803\n",
      "Epoch = 37; Discriminator Loss= 0.4310797452926636; Target Encoder Loss = 1.7012159824371338; Target ACC=0.4184862446581197\n",
      "Epoch = 38; Discriminator Loss= 0.47641369700431824; Target Encoder Loss = 1.5742276906967163; Target ACC=0.41456330128205127\n",
      "Epoch = 39; Discriminator Loss= 0.464594304561615; Target Encoder Loss = 1.530279278755188; Target ACC=0.41212606837606836\n",
      "Epoch = 40; Discriminator Loss= 0.5401943922042847; Target Encoder Loss = 1.2660706043243408; Target ACC=0.43117321047008544\n",
      "Epoch = 41; Discriminator Loss= 0.40683987736701965; Target Encoder Loss = 1.5090831518173218; Target ACC=0.4348457532051282\n",
      "Epoch = 42; Discriminator Loss= 0.4456880986690521; Target Encoder Loss = 1.5840297937393188; Target ACC=0.45098824786324787\n",
      "Epoch = 43; Discriminator Loss= 0.46871837973594666; Target Encoder Loss = 1.5480931997299194; Target ACC=0.42810162927350426\n",
      "Epoch = 44; Discriminator Loss= 0.5029006600379944; Target Encoder Loss = 1.412801742553711; Target ACC=0.41284388354700857\n",
      "Epoch = 45; Discriminator Loss= 0.44069457054138184; Target Encoder Loss = 1.5148135423660278; Target ACC=0.41003939636752135\n",
      "Epoch = 46; Discriminator Loss= 0.4800596535205841; Target Encoder Loss = 1.6263718605041504; Target ACC=0.41409588675213677\n",
      "Epoch = 47; Discriminator Loss= 0.5191366672515869; Target Encoder Loss = 1.4548635482788086; Target ACC=0.4509548611111111\n",
      "Epoch = 48; Discriminator Loss= 0.48396486043930054; Target Encoder Loss = 1.5976895093917847; Target ACC=0.44975293803418803\n",
      "Epoch = 49; Discriminator Loss= 0.41586464643478394; Target Encoder Loss = 1.6295851469039917; Target ACC=0.4695178952991453\n"
     ]
    }
   ],
   "source": [
    "CNN_target = CNN(target=True).cuda()\n",
    "\n",
    "CNN_target.load_state_dict(CNN_source.state_dict())\n",
    "\n",
    "discriminator.train()\n",
    "CNN_target.encoder.train()\n",
    "CNN_source.eval()\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer_target_encoder = optim.Adam(\n",
    "    CNN_target.encoder.parameters(),\n",
    "    lr=3e-4,\n",
    "    betas=(0.5, 0.999)\n",
    ")\n",
    "optimizer_discriminator = optim.Adam(\n",
    "    discriminator.parameters(),\n",
    "    lr=2e-4,\n",
    "    betas=(0.5, 0.999)\n",
    ")\n",
    "\n",
    "\n",
    "epochs = 50\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    discriminator.train()\n",
    "    CNN_target.encoder.train()\n",
    "    for step, ((images_target, _), (images_source, _)) in enumerate(zip(mnist_data_loader, usps_data_loader_train)):\n",
    "        \n",
    "        \n",
    "        images_source = images_source.cuda()\n",
    "        feature_source = CNN_source.encoder(images_source)\n",
    "        prediction_source = discriminator(feature_source)\n",
    "        \n",
    "        images_target = images_target.cuda()\n",
    "        feature_target = CNN_target.encoder(images_target)\n",
    "        prediction_target = discriminator(feature_target)\n",
    "        \n",
    "        label_source_domain = torch.zeros(images_source.size(0)).long().cuda()\n",
    "        label_target_domain = torch.ones(images_target.size(0)).long().cuda()\n",
    "        \n",
    "        \n",
    "        # Treinamento do Discriminator\n",
    "        descriminator_predictions = torch.cat([prediction_source, prediction_target], dim=0)\n",
    "        descriminator_target_label = torch.cat([label_source_domain, label_target_domain], dim=0)\n",
    "        descriminator_loss = criterion(descriminator_predictions, descriminator_target_label)\n",
    "        optimizer_discriminator.zero_grad()\n",
    "        descriminator_loss.backward()\n",
    "        optimizer_discriminator.step()\n",
    "        \n",
    "\n",
    "        descriminator_target_output = CNN_target.encoder(images_target)\n",
    "        descrminator_output = discriminator(descriminator_target_output)\n",
    "        loss_target = criterion(descrminator_output, label_source_domain)\n",
    "        optimizer_target_encoder.zero_grad()\n",
    "        loss_target.backward()\n",
    "        optimizer_target_encoder.step()\n",
    "        \n",
    "        \n",
    "    accuracy = 0\n",
    "    CNN_target.eval()\n",
    "\n",
    "    accuracy = 0\n",
    "    n = 0\n",
    "    for (images, ground_truth) in mnist_data_loader:\n",
    "        n+=1\n",
    "        images = images.cuda()\n",
    "        ground_truth = ground_truth.cuda()\n",
    "        prediction = CNN_target(images)\n",
    "        pred_max = prediction.data.max(1)[1]\n",
    "        accuracy += accuracy_score(ground_truth.data.cpu(), pred_max.cpu())\n",
    "        \n",
    "\n",
    "    print(f\"Epoch = {epoch}; Discriminator Loss= {descriminator_loss}; Target Encoder Loss = {loss_target}; Target ACC={accuracy/n}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bY9pHWj8v07v"
   },
   "source": [
    "## 7. Calculando Acuracia para MNIST pós adaptação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jsn1mrRzv1Ew",
    "outputId": "503857ef-f159-4421-b2ce-05982597e99f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4914863782051282"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CNN_target.eval()\n",
    "\n",
    "accuracy = 0\n",
    "n = 0\n",
    "for (images, ground_truth) in mnist_data_loader_test:\n",
    "    n+=1\n",
    "    images = images.cuda()\n",
    "    ground_truth = ground_truth.cuda()\n",
    "\n",
    "    prediction = CNN_target(images)\n",
    "    pred_max = prediction.data.max(1)[1]\n",
    "    accuracy += accuracy_score(ground_truth.data.cpu(), pred_max.cpu())\n",
    "\n",
    "# accuracy = accuracy.item()/len(mnist_data_loader_test.dataset)\n",
    "\n",
    "accuracy/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
