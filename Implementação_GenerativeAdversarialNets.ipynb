{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a1cb2e5",
   "metadata": {},
   "source": [
    "# Implementação do paper ``Generative Adversarial Networks``\n",
    "\n",
    "Esse paper introduziu um novo framework para deep learning, chamado GANs, que consiste de um gerador e um discriminador que jogam uma competição entre si com o objetivo de gerar imagens realisticas, ou seja, que o gerador consiga confundir o discriminador para que ele não saiba diferenciar uma imagem real de uma imagem gerada artificialmente.\n",
    "\n",
    "O artigo mostra que a tecnica é eficiente para gerar imagens artificiais realistas de digitos, faces e cenas naturais.\n",
    "\n",
    "*Paper disponivel em: https://arxiv.org/abs/1406.2661"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06f3194c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from torchvision import datasets, transforms\n",
    "from torch import nn, optim\n",
    "import os\n",
    "\n",
    "os.makedirs(\"./frames\", exist_ok=True)\n",
    "os.makedirs(\"./frames_test\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12bc8534",
   "metadata": {},
   "source": [
    "## 1. Download do Dataset\n",
    "\n",
    "Para essa implementação, utilizaremos o dataset MNIST. Além disso aplicaremos uma transformação simples, normalizando-o com 0.5 na media e variancia.\n",
    "\n",
    "A depender de seu hardware, será necessario diminuir o batch_size para poupar recursos no treinamento em GPU/CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d3d5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,)),\n",
    "])\n",
    "\n",
    "trainset = datasets.MNIST('./data', download=True, train=True, transform=transform)\n",
    "valset = datasets.MNIST('./data', download=True, train=False, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True)\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35183cbb",
   "metadata": {},
   "source": [
    "## 2. Criação dos Modelos\n",
    "\n",
    "Conforme descrito no paper de Ian Goodfellow, devemos criar dois modelos: discriminador e gerador.\n",
    "\n",
    "* Gerador: O gerador é uma rede com camadas lineares, que receberá um vetor de tamanho (N, L), onde L é o tamanho do espaço latente e tera como saida um vetor (N, 28*28), representando uma imagem. Essa rede será treinada para mapear um espaço latente em uma imagem, com isso, torna-se possivel gerar imagens artificiais de um determinado conjunto apenas gerando um vetor latente aleatorio!\n",
    "\n",
    "* Discriminador: Rede com camadas lineares, que, receberá uma imagem com as seguintes dimensões (N, 28*28) e terá como output um escalar entre 0 e 1. Essa rede será treinada para tentar diferenciar o que é uma image \"fake\" de uma imagem \"real\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefd5362",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a56ed05",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Descriminator(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Descriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(28*28, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "    \n",
    "    def forward(self, img):\n",
    "        return self.model(img.view(img.size(0), -1))\n",
    "        \n",
    "        \n",
    "class Generator(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(latent_size, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 28*28),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "    \n",
    "    def forward(self, z):\n",
    "        image = self.model(z)\n",
    "        return image.view(image.size(0), *(1, 28, 28))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23127d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator().cuda()\n",
    "descriminator = Descriminator().cuda()\n",
    "\n",
    "generator.train()\n",
    "descriminator.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032de592",
   "metadata": {},
   "source": [
    "## 3. Otimizador, Função de Perda e Parametros de Treinamento\n",
    "\n",
    "Para esse problema, vamos utilizar o otimizador ADAM com os parametros $lr=2\\cdot 10^{-4}$, $\\beta_1 = 0.5$ e  $\\beta_2 = 0.999$\n",
    "\n",
    "Para a função de perda, devido ao carater binario do discriminador (0 ou 1, \"Real\" ou \"Fake\"), utilizaremos a função de entropia cruzada binaria, disponibilizada pelo PyTorch via ``nn.BCELoss``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39bb27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=2e-4, betas=(0.5, 0.999))\n",
    "optimizer_D = torch.optim.Adam(descriminator.parameters(), lr=2e-4, betas=(0.5, 0.999))\n",
    "\n",
    "loss_1 = torch.nn.BCELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc673b68",
   "metadata": {},
   "source": [
    "Também definiremos que a rotina de treinamento executará 3000 epochs. Além disso, o algoritmo que estamos implementando, preve uma rotina de $K$ iterações de treinamento do discriminador antes do treinamento do gerador, portanto, para nosso caso utilizaremos $k=2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d43923",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 3000\n",
    "K = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05be53f4",
   "metadata": {},
   "source": [
    "## 4. Rotina de Treinamento\n",
    "\n",
    "Por fim, podemos implementar a rotina de treinamento. Conforme descrito no paper, a rotina de treinamento é um jogo de competição entre o gerador e o discriminador, em que, primeiramente será utilizado imagens geradas e imagens do dataset, as quais serão classificadas pelo descriminador entre \"real\" (imagem do dataset) e \"fake\" (imagem gerada pelo gerador) e passará pelo processo de backpropagation.\n",
    "\n",
    "Após essa etapa, será utilizado um conjunto de imagens \"fake\" geradas pelo gerador, que serão discriminadas e por fim, o erro da função perda será calculado considerando que as imagens representem imagens \"reais\", com o intuito de melhorar o gerador para que as imagens falsas se aproximem das imagens reais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cf82be74",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 0] Generator Loss: 0.6733267307281494; Discriminator Loss: -0.033357009291648865\n",
      "[Epoch: 100] Generator Loss: 0.0; Discriminator Loss: -50.0\n",
      "[Epoch: 200] Generator Loss: 0.0; Discriminator Loss: -50.0\n",
      "[Epoch: 300] Generator Loss: 0.0; Discriminator Loss: -50.0\n",
      "[Epoch: 400] Generator Loss: 0.0; Discriminator Loss: -50.0\n",
      "[Epoch: 500] Generator Loss: 0.0; Discriminator Loss: -50.0\n",
      "[Epoch: 600] Generator Loss: 0.0; Discriminator Loss: -50.0\n",
      "[Epoch: 700] Generator Loss: 0.0; Discriminator Loss: -50.0\n",
      "[Epoch: 800] Generator Loss: 0.0; Discriminator Loss: -50.0\n",
      "[Epoch: 900] Generator Loss: 0.0; Discriminator Loss: -50.0\n",
      "[Epoch: 1000] Generator Loss: 0.0; Discriminator Loss: -50.0\n",
      "[Epoch: 1100] Generator Loss: 0.0; Discriminator Loss: -50.0\n",
      "[Epoch: 1200] Generator Loss: 0.0; Discriminator Loss: -50.0\n",
      "[Epoch: 1300] Generator Loss: 0.0; Discriminator Loss: -50.0\n",
      "[Epoch: 1400] Generator Loss: 0.0; Discriminator Loss: -50.0\n",
      "[Epoch: 1500] Generator Loss: 0.0; Discriminator Loss: -50.0\n",
      "[Epoch: 1600] Generator Loss: 0.0; Discriminator Loss: -50.0\n",
      "[Epoch: 1700] Generator Loss: 0.0; Discriminator Loss: -50.0\n",
      "[Epoch: 1800] Generator Loss: 0.0; Discriminator Loss: -50.0\n",
      "[Epoch: 1900] Generator Loss: 0.0; Discriminator Loss: -50.0\n",
      "[Epoch: 2000] Generator Loss: 0.0; Discriminator Loss: -50.0\n",
      "[Epoch: 2100] Generator Loss: 0.0; Discriminator Loss: -50.0\n",
      "[Epoch: 2200] Generator Loss: 0.0; Discriminator Loss: -50.0\n",
      "[Epoch: 2300] Generator Loss: 0.0; Discriminator Loss: -50.0\n",
      "[Epoch: 2400] Generator Loss: 0.0; Discriminator Loss: -50.0\n",
      "[Epoch: 2500] Generator Loss: 0.0; Discriminator Loss: -50.0\n",
      "[Epoch: 2600] Generator Loss: 0.0; Discriminator Loss: -50.0\n",
      "[Epoch: 2700] Generator Loss: 0.0; Discriminator Loss: -50.0\n",
      "[Epoch: 2800] Generator Loss: 0.0; Discriminator Loss: -50.0\n",
      "[Epoch: 2900] Generator Loss: 0.0; Discriminator Loss: -50.0\n"
     ]
    }
   ],
   "source": [
    "z_test = torch.Tensor(np.random.normal(0, 1, (1, latent_size))).cuda()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    loss_g = 0\n",
    "    loss_d = 0\n",
    "\n",
    "    for k in range(K):\n",
    "        optimizer_D.zero_grad()\n",
    "        image, label = next(iter(trainloader))\n",
    "\n",
    "        image = image.cuda()\n",
    "\n",
    "        real_label = torch.ones((image.size(0), 1)).cuda()\n",
    "        fake_label = torch.zeros((image.size(0), 1)).cuda()\n",
    "\n",
    "        z = torch.Tensor(np.random.normal(0, 1, (image.size(0), latent_size))).cuda()\n",
    "        with torch.no_grad():\n",
    "            fake_imgs = generator(z)\n",
    "        fake_image_descriminated_label = descriminator(fake_imgs)\n",
    "        real_image_descriminated_label = descriminator(image.detach())\n",
    "\n",
    "        real_loss = loss_1(real_image_descriminated_label, real_label)\n",
    "        fake_loss = loss_1(fake_image_descriminated_label, fake_label)\n",
    "\n",
    "        d_loss = (real_loss/2 + (-1)*fake_loss/2)\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        loss_d += d_loss/K\n",
    "\n",
    "\n",
    "    optimizer_G.zero_grad()\n",
    "\n",
    "    z = torch.Tensor(np.random.normal(0, 1, (image.size(0), latent_size))).cuda()\n",
    "    fake_imgs = generator(z)\n",
    "    \n",
    "    fake_image_descriminated_label = descriminator(fake_imgs) \n",
    "\n",
    "    generator_loss = loss_1(fake_image_descriminated_label, real_label)\n",
    "\n",
    "    loss_g += generator_loss.item()\n",
    "\n",
    "    generator_loss.backward()\n",
    "    optimizer_G.step()\n",
    "        \n",
    "        \n",
    "    if epoch % 100 == 0:    \n",
    "        print(f\"[Epoch: {epoch}] Generator Loss: {loss_g}; Discriminator Loss: {loss_d}\")\n",
    "        fake_imgs = generator(z_test)\n",
    "        backtorgb = cv2.cvtColor(fake_imgs.cpu().detach().numpy().reshape(28, 28, 1)*255,cv2.COLOR_GRAY2RGB)\n",
    "        cv2.imwrite(f\"frames/epoch_{epoch}.jpg\", backtorgb)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4e4762",
   "metadata": {},
   "source": [
    "## 5. Verificação do Resultado do Gerador\n",
    "\n",
    "Após a rotina de treinamento, vamos gerar 10 espaços latentes aleatorios, gerar as imagens que eles representam e salvar para verificação posterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fe12edae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "\n",
    "generator.eval()\n",
    "descriminator.eval()\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    z = torch.Tensor(np.random.normal(0, 1, (1, latent_size))).cuda()\n",
    "\n",
    "    fake_imgs = generator(z)\n",
    "    backtorgb = cv2.cvtColor(fake_imgs.cpu().detach().numpy().reshape(28, 28, 1)*255,cv2.COLOR_GRAY2RGB)\n",
    "    cv2.imwrite(f\"frames_test/i_{i}.jpg\", backtorgb)\n",
    "#     plt.imshow(backtorgb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
